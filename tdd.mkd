name: inverse
layout: true
class: center, middle, inverse

---

# Test-driven development

## Radovan Bast

Licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).
Code examples: [OSI](http://opensource.org)-approved [MIT license](http://opensource.org/licenses/mit-license.html).

---

layout: false

## Testing

- **Why (principles)**
    - Motivation
    - Unit tests
    - Test-driven development
    - Functionality regression tests
    - Performance regression tests
    - Total time to test matters
    - Code coverage
    - Continuous integration

- **How (technology)**
    - Unit test frameworks (py.test, nose, Google Test, pFUnit)
    - CTest and CDash
    - runtest
    - Travis
    - Coveralls

---

## Unit tests

<img src="img/unit-testing.jpg" style="width: 350px;"/>

- https://twitter.com/dave1010/status/613601365529657344

---

## Motivation (1/2)

- As projects grow, it becomes easier to break things
- In particular for non-modular entangled projects (effects at distance)
- Testing helps detecting errors early:
  programming without constantly testing your changes will introduce errors
  and it is extremely time consuming to detect and fix them
- Interpreted imperative languages need to be tested
- So do compiled languages but the compiler catches at least some errors

---

## Motivation (2/2)

- Tests make it easier for new people to modify/reuse your code
- If you do not have (good) tests:
    - Newcomers will break the code
    - Newcomers will be scared of modifying your code
    - You get less contributors and contributions
    - You will break the code
    - You will at some point publish wrong numbers (no fun)
- Tests make it easier for computing center personnel to check that the code
  has been correctly installed

---

## Unit tests

- Test one unit: module or even single function
- Sharpen interfaces
- Speed up testing
- Good documentation of the capability and dependencies of a module
- In fact it is a documentation that is up to date by definition

---

## Test-driven development

- Write tests before writing code
- Very often we know the result that a function is supposed to produce
- Development cycle:
    - Write the test
    - Write an empty function template
    - Test that the test fails
    - Program until the test passes
    - Move on
- Avoids "gold-plating" the code

---

## Functionality regression tests

- Like in a car assembly we have to test all components and also whether the components work together
- Typically tests entire code for a set of input examples and compares them with reference outputs
- Hopefully with numerical tolerance
- Typically we need both unit and functionality regression tests
- Both are no guarantee that the code is correct "always"

---

## Performance regression tests

- Real example
    - In one code module somebody forgot and committed debug code
    - This did not break functionality
    - It slowed down that part of the code by factor 2
    - Nobody noticed for one year because we had no automatic detection of performance degradation

- Good idea
    - Create benchmark calculations to cover various performance-critical modules
    - Run these benchmarks regularly (weekly?)
    - Monitor the timing (CDash records timing)
    - If timing changes significantly, alarm bells should be ringing

---

## Total time to test matters

- You should require developers to run the test set before each `git push`
- Professional projects require running the test set before each commit
- In extreme cases after each save
- With a `pre-commit` hook you can make sure that commits that break tests are rejected
- Total time to test matters
- If the test set takes 7 hours to run, it is likely that nobody will run it
- Identify fast essential test set that has sufficient coverage and is sufficiently
  short to be run before each commit or push

---

## Code coverage

- If I break the code and all tests pass who is to blame?
- A code that is not tested will break sooner or later
- Code coverage measures and documents which lines of code have been traversed during a test run
- It is possible to have line-by-line coverage (example later)
- In all the files that have zero coverage you can multiply all numbers with 10E5 and all tests
  will happily pass

---

## Continuous integration

- Merge and test all developer working copies with a shared mainline several times a day
- Possibly after each commit
- Avoid "integration hell"
- Makes it possible for the mainline maintainer to see whether a modification
  breaks functionality before merging it manually

---

## Good practices (1/2)

- Test before committing (use the Git staging area)
- Fix broken tests immediately (dirty dishes effect)
- Do not deactivate tests "temporarily"
- Think about coverage (physics and lines of code)
- Go public with your testing dashboard and issues/tickets
- Dogfooding: use the code/scripts that you ship

---

## Good practices (2/2)

- Think about input sanitization (green testing dashboard does not prevent me from making unexpected keyword combinations)
- Test controlled errors: if something is expected to fail, test for that
- Make testing easy to run (`make test`)
- Make testing easy to analyze
    - Do not flood screen with pages of output in case everything runs OK
    - Test with numerical tolerance (extremely annoying to compare digits by eye)

---

## Unit test frameworks

- Python
    - py.test
    - nose
    - doctest

- C(++)
    - Google Test
    - CppUnit
    - Boost.Test
    - UnitTest++

- Fortran
    - pFUnit
    - Fruit

---

## py.test

- Very easy to set up

```shell
$ pip install pytest # ideally into a virtualenv
```

- Very easy to use

```python
def add_numbers(f1, f2):
    return f1 + f2

def test_add_numbers():
    assert (add_numbers(1.0, 2.0) == 3.0)
```

- Example output: https://travis-ci.org/bast/pytest-demo/builds/40930408
- Example project: https://github.com/bast/pytest-demo

---

## Google Test

- Widely used
- Very rich in functionality
- Source: https://github.com/svn2github/googletest.git

```cpp
#include "gtest/gtest.h"
#include "example.h"

TEST(example, add)
{
    double res;
    res = add_numbers(1.0, 2.0);
    ASSERT_NEAR(res, 3.0, 1.0e-11);
}
```

- Example output: https://travis-ci.org/bast/gtest-demo/builds/41003659
- Example project: https://github.com/bast/gtest-demo

---

## pFUnit

- Very rich in functionality
- Source: http://pfunit.sourceforge.net
- Requires modern Fortran compilers (uses F2003 standard)

```fortran
@test
subroutine test_add_numbers()

   use hello
   use pfunit_mod

   implicit none

   real(8) :: res

   call add_numbers(1.0d0, 2.0d0, res)
   @assertEqual(res, 3.0d0)

end subroutine
```

- Example output: https://travis-ci.org/bast/pfunit-demo/builds/40946796
- Example project: https://github.com/bast/pfunit-demo

---

## CTest and CDash

- CTest runs a set of tests through bash/perl/python scripts and reports to CDash which aggregates results
- The test scripts can be anything you like

```shell
add_test(my_test_name ${PROJECT_BINARY_DIR}/my_test_script --flags)

include(CTest)
enable_testing()
```

- CTest looks for the return codes: 0/non-0 (success/failure)
- CTest is a powerful test runner, no need to implement one
- Reporting to CDash is easy

```shell
$ make Nightly
```

- CDash example: https://repo.theochem.kth.se/cdash/

---

## runtest

- Numerically tolerant test library
- http://runtest.readthedocs.org
- https://github.com/bast/runtest

```python
#!/usr/bin/env python

import os
import sys

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from runtest_dirac import Filter, TestRun

test = TestRun(__file__, sys.argv)

f = Filter()
f.add(from_string   = '@   Elements of the electric dipole',
      to_string     = '@   anisotropy',
      rel_tolerance = 1.0e-5)
f.add(from_string   = '************ Expectation values',
      to_string     = 's0 = T : Expectation value',
      rel_tolerance = 1.0e-5)

test.run(['PBE0gracLB94.inp', 'GLLBsaopLBalpha.inp'], ['Ne.mol'], f)

sys.exit(test.return_code)
```

---

## Travis CI

- https://travis-ci.org
- Free for public repositories
- Easy integration with GitHub
- Host entire build and test history
- Example: https://travis-ci.org/bast/xcint/builds

## Coveralls: code coverage history and stats

- https://coveralls.io
- Free for public repositories
- Easy integration with GitHub
- Host entire test coverage history
- Example: https://coveralls.io/r/bast/pytest-demo?branch=master

---

## Fun: Jenkins Chuck Norris plugin

https://wiki.jenkins-ci.org/display/JENKINS/ChuckNorris+Plugin

<img src="img/chucknorris_badass.jpg" style="width: 350px;"/>
<img src="img/chucknorris_thumbup.jpg" style="width: 350px;"/>

---

## Fun: Jenkins "Extreme Feedback" Contraption

https://github.com/codedance/Retaliation

"Retaliation is a Jenkins CI build monitor that automatically coordinates a foam missile counter-attack against the developer who breaks the build. It does
this by playing a pre-programmed control sequence to a USB Foam Missile Launcher to target the offending code monkey."

<img src="img/launcher.jpg" style="width: 400px;"/>

---

## Summary

- There are many tools out there
- We have not covered all of them
- Automated testing (in one form or another) is a must
- Think about test coverage
